{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoegifx4RSZV18buA35ceK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinKotgire/LLM-with-KG-step-by-step/blob/Prop_rel_for_all_nodes/Chunking_in_a_tree_(fairer).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrYplwbZWx6O"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF -q  # For reading PDF content\n",
        "!pip install PyPDF2 -q  # Alternative library for PDF manipulation\n",
        "!pip install openai -q\n",
        "!pip install langchain -q\n",
        "\n",
        "!pip install retry -q\n",
        "!pip install openai -q\n",
        "!pip install langchain -q\n",
        "!pip install retry -q\n",
        "!pip install neo4j -q\n",
        "!pip install -qU langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from typing import List,Dict\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from collections import OrderedDict\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-proj-DIw5v0yjnniYJXXhtrjST3BlbkFJ4mXRcu6kwfijxk58IQkJ'\n",
        "os.environ[\"NEO4J_URI\"] = 'neo4j+s://39944eda.databases.neo4j.io'\n",
        "os.environ[\"NEO4J_USERNAME\"] = 'neo4j'\n",
        "os.environ[\"NEO4J_PASSWORD\"] = 'cPhru78a_ORF-prPynqZ3XjUEXjaY5Z1V4ist9H1AV4'\n",
        "\n",
        "client = OpenAI()\n",
        "from retry import retry\n",
        "class agent:\n",
        "  def __init__(self,client=None,model=\"gpt-3.5-turbo-0125\",prompt_template=None):\n",
        "    self.client=client\n",
        "    self.model=model\n",
        "    self.messages=[]\n",
        "    self.prompt_template=prompt_template\n",
        "  def prompt_from_template(self,template,dict1):\n",
        "    try :\n",
        "      return template.format(**dict1)\n",
        "    except Exception as e:\n",
        "      return \"Not valid dictionary for the tempalte\"\n",
        "\n",
        "  def run_prompt(self,prompt)    :\n",
        "    response = self.client.chat.completions.create(\n",
        "         model=self.model,\n",
        "         messages=[{\"role\": \"system\", \"content\": \"You are Mutual Funds Support Copilot for OpenXfi.\"},\n",
        "          {\"role\":\"user\",\"content\":prompt}])\n",
        "    self.messages=[]\n",
        "    self.messages=[{\"role\":\"user\",\"content\":prompt},\n",
        "     {\"role\":\"assistant\",\"content\":response.choices[0].message.content}]\n",
        "    print(len(self.messages))\n",
        "    return response.choices[0].message.content\n",
        "  def run_are_u_sure(self,extention=None)  :\n",
        "    self.messages.append({\"role\":\"user\",\"content\":\"Please Re-evaluate.\"+extention})\n",
        "    response = self.client.chat.completions.create(\n",
        "         model=self.model,\n",
        "         messages=self.messages)\n",
        "    self.messages=[{\"role\":\"user\",\"content\":\"Please Re-evaluate.\"+extention},{\"role\":\"user\",\"content\":response.choices[0].message.content}]\n",
        "    return response.choices[0].message.content\n",
        "  def extract_from_string(self,string_)  :\n",
        "    # end=string_.find('<')\n",
        "    matches=string_\n",
        "    if('json' in string_) :\n",
        "      pattern = r'```json\\s*([\\s\\S]+?)\\s*```'\n",
        "    # Find all matches\n",
        "      matches = re.findall(pattern, string_)[0]\n",
        "    elif('python' in string_):\n",
        "      pattern = r'```python\\s*([\\s\\S]+?)\\s*```'\n",
        "      matches = re.findall(pattern, string_)[0]\n",
        "\n",
        "    list_string = matches[:]\n",
        "    output_list = eval(list_string)\n",
        "    return output_list\n",
        "  @retry(exceptions=Exception, tries=3, delay=1)\n",
        "  def complete_run(self,template,question:Dict,are_you_sure=None,verbose=False)  :\n",
        "    prompt=self.prompt_from_template(template,question)\n",
        "    o=self.run_prompt(prompt)\n",
        "    if(verbose==True):\n",
        "      print(o)\n",
        "    # time.sleep(20)\n",
        "    if(are_you_sure!=None):\n",
        "      o=self.run_are_u_sure(are_you_sure)\n",
        "      # time.sleep(20)\n",
        "      print(o)\n",
        "    o=self.extract_from_string(o)\n",
        "    # print(o)\n",
        "    return o\n",
        "agent_=agent(client)\n"
      ],
      "metadata": {
        "id": "sVP0lV3IXZG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = Neo4jGraph(url=os.environ[\"NEO4J_URI\"], username='neo4j', password=os.environ[\"NEO4J_PASSWORD\"])\n",
        "def exceute_cypher(graph,cyphers:List,verbose=False):\n",
        "  print('Executing cyphers______________________')\n",
        "  i=0\n",
        "  for c in cyphers:\n",
        "    # if verbose :print(c)\n",
        "    # try:\n",
        "    print(i)\n",
        "    graph.query(c)\n",
        "    # except Exception  as e:\n",
        "    #   print('\\n\\nExecute graph query error::', i,'\\n\\n')\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "SCsd1OhPXgZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    doc = fitz.open(pdf_file)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    doc.close()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "_WONqUnyZCe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "id=0\n",
        "\n",
        "def split_the_document(text:str,chunksize,parent:str,name:str,o):\n",
        "  global id\n",
        "  if(chunksize<=300):\n",
        "    child=f\"{name}_Chunk {id}\"\n",
        "    id+=1\n",
        "\n",
        "    # print('----------------------------------------------------------'*5)\n",
        "    # print('Parent:',parent,'\\t\\tChild:',child,'\\t',len(text))\n",
        "    o.append([parent,child,text])\n",
        "    return parent,child,text\n",
        "  chunksize=int(chunksize/5)\n",
        "  text_splitter = RecursiveCharacterTextSplitter(separators=['\\n\\n\\n','.','\\n'],chunk_size = chunksize, chunk_overlap=int(chunksize/10))\n",
        "  chunks=text_splitter.create_documents([text])\n",
        "  a=[]\n",
        "  p=f\"{name}_Chunk {id}\"\n",
        "  id+=1\n",
        "  o.append([parent,p,text])\n",
        "  for chunk in chunks:\n",
        "\n",
        "    pp,cc,text_=split_the_document(chunk.page_content,chunksize,p,name,o)\n",
        "    a.append(text_)\n",
        "\n",
        "\n",
        "  return parent,p,''.join(a)\n",
        "\n",
        "\n",
        "\n",
        "o=[]\n",
        "text=split_the_document(extract_text_from_pdf(pdf_path),10000,'FINAL_AIF (Category III) Distributors_Version-June-2023e.pdf','FINAL_AIF (Category III) Distributors_Version-June-2023e.pdf',o)\n",
        "id"
      ],
      "metadata": {
        "id": "VzAbvD4CXnXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_cypher(p_c_t):\n",
        "  cypher_template=\"\"\"MAtch (node1:nodes {{id: \"{node1_id}\"}})\n",
        "\n",
        "    MERGE (node2:nodes:tembedable {{id: '{node2_id}'}})\n",
        "    ON CREATE SET node2.name = '{Node2Name}', node2.text = \"{Node2Text}\"\n",
        "    MERGE (node1)-[:is_parent_of]->(node2)\n",
        "    RETURN node1, node2\n",
        "    \"\"\"\n",
        "    #     ON CREATE SET node1.name = '{node1_id}' ,node1.type='pdf\n",
        "  cyphers=[]\n",
        "\n",
        "  root_node=p_c_t[0][0]\n",
        "  root_c=f\"CREATE (n:nodes:Pdf {{name: '{root_node}', id: '{root_node}', type: 'txt'}}) RETURN n\"\n",
        "  cyphers.append(root_c)\n",
        "\n",
        "  for a in p_c_t:\n",
        "    text=a[2]\n",
        "    text=text.replace('\"','')\n",
        "    c=cypher_template.format(**{'node1_id':a[0],'node2_id':a[1],'Node2Name':a[1],'Node2Text':text})\n",
        "    cyphers.append(c)\n",
        "  return cyphers\n",
        "cyphers=create_cypher(o)\n",
        "exceute_cypher(graph,cyphers,False)"
      ],
      "metadata": {
        "id": "4SkWrAPMX1BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "import json\n",
        "from pprint import pprint\n",
        "directory='/content/PDF'\n",
        "files=listdir(directory)\n",
        "Outputs=[]\n",
        "i=0\n",
        "\n",
        "for file_ in files:\n",
        "  # try:\n",
        "  global id\n",
        "  o=[]\n",
        "  id=0\n",
        "  print(i,'_'*100)\n",
        "  print(file_)\n",
        "  file_path=directory+'/'+file_\n",
        "  if(file_path in Outputs):\n",
        "    continue\n",
        "  chunks=split_the_document(extract_text_from_pdf(file_path),10000,file_,file_,o)\n",
        "\n",
        "  cyphers=create_cypher(o)\n",
        "  print(len(o),len(cyphers))\n",
        "  exceute_cypher(graph,cyphers,False)\n",
        "  Outputs.append(file_path)\n",
        "  # Print the positions (chapter number, page number, start position)\n",
        "  i+=1\n"
      ],
      "metadata": {
        "id": "yz_r83KOX-at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
      ],
      "metadata": {
        "id": "mdlM5BD8YDew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(labels:str,node_properties:List,index_name:str,embedding_node_property:str,embeddings,only_retrieve=True):\n",
        "  # for label in labels:\n",
        "  if(only_retrieve==False):\n",
        "    Neo4jVector.from_existing_graph(\n",
        "      embedding=embeddings,\n",
        "      url=os.environ[\"NEO4J_URI\"], username=os.environ[\"NEO4J_USERNAME\"], password=os.environ[\"NEO4J_PASSWORD\"],\n",
        "      text_node_properties=node_properties,\n",
        "      embedding_node_property=embedding_node_property,\n",
        "      index_name=index_name,\n",
        "      node_label=labels\n",
        "    )\n",
        "    print('Embedding for label::',labels,'  created.')\n",
        "  vector_index = Neo4jVector.from_existing_index(\n",
        "    embedding=embeddings,\n",
        "    url=os.environ[\"NEO4J_URI\"], username=os.environ[\"NEO4J_USERNAME\"], password=os.environ[\"NEO4J_PASSWORD\"],index_name=index_name)\n",
        "  return vector_index\n",
        "# def retrieve_index"
      ],
      "metadata": {
        "id": "MRMpYyRaYFam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vextor_name=create_index(labels='leaf',node_properties=['text'],index_name=\"Index_embeddings_on_text\",embedding_node_property='embedding',embeddings=embeddings)"
      ],
      "metadata": {
        "id": "OSeVrh4nYHfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_graph(question:str,vector_database,graph,verbose=False):\n",
        "  docs_with_score=vector_database.similarity_search_with_score(question,k=30)\n",
        "  metadatas=[d[0].metadata['name'] for d in docs_with_score]\n",
        "  cypher_for_gp=\"\"\"MATCH (leaf:leaf {{name: '{leaf_name}'}})<-[:is_parent_of]-(parent:nodes)<-[:is_parent_of]-(gp:nodes)\n",
        "WHERE NOT (leaf)-->()  // Ensures that the node is a leaf node\n",
        "RETURN parent.name,parent.charlen,gp.name,gp.charlen\n",
        "\"\"\"\n",
        "  def remove_duplicates_ordered(input_list):\n",
        "    return list(OrderedDict.fromkeys(input_list).keys())\n",
        "  graphs_o=[]\n",
        "  for m in metadatas:\n",
        "    cy=cypher_for_gp.format(**{'leaf_name':m})\n",
        "    o=graph.query(cy)\n",
        "    graphs_o.append(o)\n",
        "  nodes=[]\n",
        "  for g in graphs_o:\n",
        "    if(g[0]['gp.charlen']<=20000):\n",
        "      nodes.append(g[0]['gp.name'])\n",
        "    else:\n",
        "      nodes.append(g[0]['parent.name'])\n",
        "  # pprint(nodes)\n",
        "  nodes=remove_duplicates_ordered(nodes)\n",
        "  # pprint(nodes)\n",
        "  c2=f\"\"\" Match (n:nodes) where n.name in {nodes} return n.text\"\"\"\n",
        "  contexts=graph.query(c2)\n",
        "  if (verbose==True):pprint(contexts)\n",
        "  context=[con['n.text'] for con in contexts]\n",
        "  context='\\n'.join(context)\n",
        "  return context\n",
        "cont=get_data_from_graph('What are arbitrage mutual funds?',vextor_name,graph)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xM5vF2gNYL4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_kg(agent_to_chat:agent,kg,vector_name_index,question:str,verbose=False):\n",
        "\n",
        "\n",
        "  docs=get_data_from_graph(question,vector_name_index,kg,verbose=verbose).replace('Groww','Openxfi')[0:25000]\n",
        "\n",
        "  p2=f\"\"\"\n",
        "You are a Mutual Funds Support Copilot for Openxfi who uses Knowldege graph for refence.\n",
        "You are given a question.\n",
        "Question : {question}\n",
        "Important : Always give a detailed answer but it should be crisp and to the point.\n",
        "Very Important :: Only answer the question and nothing else. If the question is not valid say the question is not valid .\n",
        "Very Important : If the answer is insufficient/incomplet to the question reply with \" If you think This doesn't answer your query you can contact hello@openxfi.com .\"\n",
        "Following is the extracted context. Use it to answer the question.\n",
        "\n",
        "\\Data::\\n{docs}\n",
        "\n",
        "Question :{question}\n",
        "Answer :\n",
        "  \"\"\"\n",
        "\n",
        "  answer=agent_to_chat.run_prompt(p2)\n",
        "  return answer\n"
      ],
      "metadata": {
        "id": "G4UEcUt-YN7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question='How to do KYC?'\n",
        "chat_with_kg(agent_,graph,vextor_name,question,verbose=False)"
      ],
      "metadata": {
        "id": "oYA6H3CfYR8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}