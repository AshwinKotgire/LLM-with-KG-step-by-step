{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6ApHZveAcfA0U9hBAFTkg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinKotgire/LLM-with-KG-step-by-step/blob/Prop_rel_for_all_nodes/Full_Stack_Retieval_step_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ2BvzxrI7Pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb0a446-a72e-4602-9bdb-f6cc8a97c634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting neo4j\n",
            "  Downloading neo4j-5.19.0.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2023.4)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-5.19.0-py3-none-any.whl size=280741 sha256=50ef30f93b88720abc76aa9f2282834e40198802478470952320a260b380cfe4\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/db/9b/2cfde1fa33145219c0322f299b604daf5aba2ed443a7ed5f07\n",
            "Successfully built neo4j\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-5.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai -q\n",
        "!pip install langchain -q\n",
        "!pip install retry -q\n",
        "!pip install neo4j\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from dotenv import load_dotenv\n",
        "import os\n",
        "from pprint import pprint\n",
        "import re\n",
        "# Common data processing\n",
        "import json\n",
        "import textwrap\n",
        "from typing import List,Dict\n",
        "# Langchain\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "# from langchain_openai import ChatOpenAI\n",
        "from retry import retry\n",
        "from os import listdir\n",
        "\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import json\n",
        "from retry import retry\n",
        "# import os\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "VGVkAFb5OTNq"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GFiUvLGhrSJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "os.environ[\"NEO4J_URI\"] = 'neo4j+s://4469cbdc.databases.neo4j.io'\n",
        "os.environ[\"NEO4J_USERNAME\"] = 'neo4j'\n",
        "os.environ[\"NEO4J_PASSWORD\"] = '2mFdM_33Bx5KUR_2v2UcX7itdIJVNyZC9blMM5vHWvA'\n"
      ],
      "metadata": {
        "id": "kpEB7gLEON4T"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "\n",
        "class agent:\n",
        "  def __init__(self,client=None,model=\"gpt-3.5-turbo-0125\",prompt_template=None):\n",
        "    self.client=client\n",
        "    self.model=model\n",
        "    self.messages=[]\n",
        "    self.prompt_template=prompt_template\n",
        "  def prompt_from_template(self,template,dict1):\n",
        "    try :\n",
        "      return template.format(**dict1)\n",
        "    except Exception as e:\n",
        "      return \"Not valid dictionary for the tempalte\"\n",
        "\n",
        "  def run_prompt(self,prompt)    :\n",
        "    response = self.client.chat.completions.create(\n",
        "         model=self.model,\n",
        "         messages=[{\"role\": \"system\", \"content\": \"You are Mutual Funds Support Copilot for OpenXfi.\"},\n",
        "          {\"role\":\"user\",\"content\":prompt}])\n",
        "    self.messages=[]\n",
        "    self.messages=[{\"role\":\"user\",\"content\":prompt},\n",
        "     {\"role\":\"assistant\",\"content\":response.choices[0].message.content}]\n",
        "    print(len(self.messages))\n",
        "    return response.choices[0].message.content\n",
        "  def run_are_u_sure(self,extention=None)  :\n",
        "    self.messages.append({\"role\":\"user\",\"content\":\"Please Re-evaluate.\"+extention})\n",
        "    response = self.client.chat.completions.create(\n",
        "         model=self.model,\n",
        "         messages=self.messages)\n",
        "    self.messages=[{\"role\":\"user\",\"content\":\"Please Re-evaluate.\"+extention},{\"role\":\"user\",\"content\":response.choices[0].message.content}]\n",
        "    return response.choices[0].message.content\n",
        "  def extract_from_string(self,string_)  :\n",
        "    # end=string_.find('<')\n",
        "    matches=string_\n",
        "    if('json' in string_) :\n",
        "      pattern = r'```json\\s*([\\s\\S]+?)\\s*```'\n",
        "    # Find all matches\n",
        "      matches = re.findall(pattern, string_)[0]\n",
        "    elif('python' in string_):\n",
        "      pattern = r'```python\\s*([\\s\\S]+?)\\s*```'\n",
        "      matches = re.findall(pattern, string_)[0]\n",
        "\n",
        "    list_string = matches[:]\n",
        "    output_list = eval(list_string)\n",
        "    return output_list\n",
        "  @retry(exceptions=Exception, tries=3, delay=1)\n",
        "  def complete_run(self,template,question:Dict,are_you_sure=None,verbose=False)  :\n",
        "    prompt=self.prompt_from_template(template,question)\n",
        "    o=self.run_prompt(prompt)\n",
        "    if(verbose==True):\n",
        "      print(o)\n",
        "    # time.sleep(20)\n",
        "    if(are_you_sure!=None):\n",
        "      o=self.run_are_u_sure(are_you_sure)\n",
        "      # time.sleep(20)\n",
        "      print(o)\n",
        "    o=self.extract_from_string(o)\n",
        "    # print(o)\n",
        "    return o\n",
        "agent_=agent(client)\n"
      ],
      "metadata": {
        "id": "g4zIbvtSrUSR"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = Neo4jGraph(url='neo4j+s://4469cbdc.databases.neo4j.io', username='neo4j', password='2mFdM_33Bx5KUR_2v2UcX7itdIJVNyZC9blMM5vHWvA')"
      ],
      "metadata": {
        "id": "JXWSZU0WOVsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory='/content/All Data'\n",
        "files=listdir(directory)\n"
      ],
      "metadata": {
        "id": "msl0hbJMsXxA"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQK3XCCd2kAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"You are provided with the names of list of documents and a question. You have to tell which document can have the answer to the question.\n",
        "Answer in this JSON format : {{'Most rel Doc':MOST RELEVANT DOCUMENT}}\n",
        "If you think no document can best answer the question, then return {{'Most rel Doc':\"Answer on your own.\"}}\n",
        "Question :{question}\n",
        "List of Documents :{doc_list}\n",
        "\"\"\"\n",
        "question='Which are the best Mutual Fund Houses in india?'\n",
        "\n",
        "\n",
        "most_rd=agent_.complete_run(prompt,{'question':question,'doc_list':files}).get('Most rel Doc')\n",
        "print(most_rd)\n",
        "if(most_rd!=\"Answer on your own.\"):\n",
        "  file_path=directory+'/'+most_rd\n",
        "  data=open(file_path, 'r').read()\n",
        "  data=data.replace(\"Groww\", \"Openxfi\")\n",
        "else:\n",
        "  data=\"\"\"I currently am unable to answer your query. Please contact Openxfi @ support@Openxfi.com , Sorry for your Inconvenience.\"\"\"\n",
        "system_message=\"\"\"Groww is a financial technology company based in India that offers an online platform for individuals to invest in mutual funds, stocks, exchange-traded funds (ETFs), and other investment products. Founded in 2024, Groww aims to simplify the investment process and make it accessible to a wide range of people, including those who may not have extensive financial knowledge or experience.\n",
        "The platform provides users with tools and resources to research and analyze various investment options, as well as the ability to invest directly through the platform. Groww's user-friendly interface, educational content, and low fees have contributed to its popularity among retail investors in India.\n",
        "As of my last update, Groww has grown rapidly and has become one of the leading investment platforms in India, attracting millions of users. It continues to expand its offerings and services to cater to the evolving needs of investors.\n",
        "\"\"\".replace(\"Groww\", \"Openxfi\")\n",
        "p2=f\"\"\"{system_message}\n",
        "You are a Mutual Funds Support Copilot for Openxfi who uses Knowldege graph for refence.\n",
        "  You were provided with a question by the customer and you had to extract all the entities from the question which could be used to query the knowledge graph and extract context.\n",
        "  After that those were used to query graph and get context.\n",
        "  Following is the context extracted.Use it to answer the question.\n",
        "  Answer the question based on context in Natual Language only.\n",
        "  Important: Answer truthfully and to the point and just say I dont know if you do not.\n",
        "  Important :: Do not use 'Based on context provided' EVER. Instead use 'As per my best knowledge'.\n",
        "  Question:{question}\n",
        "  \\nContext::\\n{data}\n",
        " \"\"\"\n",
        "\n",
        "answer=agent_.run_prompt(p2)\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "aKk4kDkvq_YR",
        "outputId": "3dd956ed-860c-43ae-dff5-29b2942d998e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Mutual Fund Houses\n",
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As per my best knowledge, some of the best mutual fund houses in India are:\\n\\n1. SBI Mutual Fund\\n2. ICICI Prudential Mutual Fund\\n3. HDFC Mutual Fund\\n4. Aditya Birla Sun Life Mutual Fund\\n5. Kotak Mahindra Mutual Fund\\n6. Nippon India Mutual Fund\\n7. Axis Mutual Fund\\n8. UTI Mutual Fund\\n9. IDFC Mutual Fund\\n10. DSP Mutual Fund\\n\\nThese mutual fund houses are among the top choices for investors in India based on their reputation, performance history, asset size, fund management, and other factors to consider before investing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_message=\"\"\"Groww is a financial technology company based in India that offers an online platform for individuals to invest in mutual funds, stocks, exchange-traded funds (ETFs), and other investment products. Founded in 2024, Groww aims to simplify the investment process and make it accessible to a wide range of people, including those who may not have extensive financial knowledge or experience.\n",
        "The platform provides users with tools and resources to research and analyze various investment options, as well as the ability to invest directly through the platform. Groww's user-friendly interface, educational content, and low fees have contributed to its popularity among retail investors in India.\n",
        "As of my last update, Groww has grown rapidly and has become one of the leading investment platforms in India, attracting millions of users. It continues to expand its offerings and services to cater to the evolving needs of investors.\n",
        "\"\"\".replace(\"Groww\", \"Openxfi\")\n",
        "system_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "wxLrc9UEzANi",
        "outputId": "24fa986b-3a55-45ad-df84-a92444ed41e7"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Openxfi is a financial technology company based in India that offers an online platform for individuals to invest in mutual funds, stocks, exchange-traded funds (ETFs), and other investment products. Founded in 2024, Openxfi aims to simplify the investment process and make it accessible to a wide range of people, including those who may not have extensive financial knowledge or experience.\\nThe platform provides users with tools and resources to research and analyze various investment options, as well as the ability to invest directly through the platform. Openxfi's user-friendly interface, educational content, and low fees have contributed to its popularity among retail investors in India.\\nAs of my last update, Openxfi has grown rapidly and has become one of the leading investment platforms in India, attracting millions of users. It continues to expand its offerings and services to cater to the evolving needs of investors.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_string(input_string):\n",
        "    # Replace multiple white spaces with a single space\n",
        "    cleaned_string = re.sub(r'\\s+', ' ', input_string).strip()\n",
        "    # Remove .txt extension\n",
        "    cleaned_string = re.sub(r'\\.txt$', '', cleaned_string)\n",
        "    # Remove leading and trailing whitespace\n",
        "    cleaned_string = cleaned_string.strip()\n",
        "    return cleaned_string\n",
        "\n",
        "# Example usage\n",
        "file_name = \"  example document.txt  \"\n",
        "cleaned_name = clean_string(file_name)\n",
        "print(cleaned_name)  # Output will be \"example_document\"\n",
        "def remove_space(stri,with_='_'):\n",
        "  x=stri.replace(' ',with_).replace('-','').replace('?','')\n",
        "  if x[0].isdigit():\n",
        "    x='_'+x\n",
        "  return x\n",
        "def exceute_cypher(graph,cyphers:List,verbose=False):\n",
        "  print('Executing cyphers______________________')\n",
        "  for c in cyphers:\n",
        "    if verbose :print(c)\n",
        "    try:\n",
        "      graph.query(c)\n",
        "    except Exception  as e:\n",
        "      print('\\n\\nExecute graph query error::', c,'\\n\\n')\n",
        "def merge_dicts(list_of_dicts):\n",
        "    merged_dict = {}\n",
        "    for d in list_of_dicts:\n",
        "        merged_dict.update(d)\n",
        "    return merged_dict\n",
        "def unnest_dict(nested_dict, parent_key=''):\n",
        "    unnested_dict = {}\n",
        "    for key, value in nested_dict.items():\n",
        "        new_key = f\"{parent_key}_{key}\" if parent_key else key\n",
        "        if isinstance(value, dict):\n",
        "            unnested_dict.update(unnest_dict(value, new_key))\n",
        "        else:\n",
        "            if(type(value)==list):\n",
        "              value=\", \".join(value)\n",
        "            unnested_dict[new_key] = str(value).replace(\"'\",\"\")\n",
        "    return unnested_dict\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_text(file_path):\n",
        "    # Match the text between last / and .txt\n",
        "    match = re.search(r'[^/]+(?=\\.txt)', file_path)\n",
        "    if match:\n",
        "        return match.group(0)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "file_path = \"/path/to/your/folder/example_document.txt\"\n",
        "text = extract_text(file_path)\n",
        "print(text)  # Output will be \"example_document\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE4gZ4vZOfHx",
        "outputId": "8135aa0e-30c7-4e9a-ed2b-f28947272dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_nodes(entities:List,properties,verbose=False):\n",
        "  cyphers=[]\n",
        "  nodes=[]\n",
        "  for e in entities:\n",
        "    e_=e\n",
        "    # if re.search(r'faq', e, re.IGNORECASE):\n",
        "    #   e_=e+entities[0]\n",
        "    #   print(e_)\n",
        "    # if re.search(r'Q\\d+', e):\n",
        "    #     e_=entities[0]+e\n",
        "    e_=e.replace(\"'\",\"\").replace(\"-\",\"\").upper()\n",
        "    nodes.append(e_)\n",
        "    try:\n",
        "      type_=remove_space(properties[e]['type']).replace(\"'\",\"\").replace(\"-\",\"\").replace('?','.').capitalize()\n",
        "      # print(type_)\n",
        "    except Exception as e:\n",
        "      type_='Entity'\n",
        "    cypher=f\"Merge (:{type_} {{name:'{e_}'}})\"\n",
        "\n",
        "    if(verbose)    :print(cypher)\n",
        "    cyphers.append(cypher)\n",
        "  return cyphers,nodes\n",
        "def add_properties(properties:Dict,entities,name=None,verbose=False):\n",
        "  cyphers=[]\n",
        "  nodes=[]\n",
        "  for e in entities:\n",
        "    e_=e.replace(\"'\",\"\").replace(\"-\",\"\")\n",
        "    property_=properties[e]\n",
        "    # print(e_)\n",
        "    if(type(property_)==list):\n",
        "      # print('Merging dicts')\n",
        "      property_=merge_dicts(property_)\n",
        "    property_ = unnest_dict(property_)\n",
        "    try:\n",
        "      type_=remove_space(properties[e]['type']).replace(\"'\",\"\").replace(\"-\",\"\").replace('?','.').capitalize()\n",
        "      # print(type_)\n",
        "    except Exception as e:\n",
        "      type_='Entity'\n",
        "    # print(type_)\n",
        "    cypher=f\"Merge (e:{type_}{{name:'{e_}'}})\"\n",
        "\n",
        "    p2=\" ,\".join([f\"e.`{k1}`='{v1}'\" for k1,v1 in property_.items()])\n",
        "    cyphers.append(cypher + ' SET '+p2)\n",
        "    nodes.append(e_)\n",
        "    # print(cypher + ' SET '+p2)\n",
        "  return cyphers,nodes"
      ],
      "metadata": {
        "id": "vjE74a3ySe3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory='/content/All Data'\n",
        "files=listdir(directory)\n",
        "Outputs={}\n",
        "entities=[]\n",
        "file_names={}\n",
        "i=0\n",
        "for file_ in files:\n",
        "  # try:\n",
        "  print(file_)\n",
        "  file_names[file_]=clean_string(file_).replace(\"'\",\"\").replace(\"-\",\"\").upper()\n",
        "  file_path=directory+'/'+file_\n",
        "  data=open(file_path, 'r').read()\n",
        "  data=data.replace(\"Groww\", \"Openxfi\")\n",
        "  file_=clean_string(file_)\n",
        "  Outputs[file_.replace(\"'\",\"\").replace(\"-\",\"\").upper()]={\"text\":data,'type':'Document data'}\n",
        "  entities.append(file_)\n",
        "cyphers_create_nodes,nodes=create_nodes(entities,Outputs,verbose=False)\n",
        "print(cyphers_create_nodes)\n",
        "# exceute_cypher(graph,cyphers_create_nodes,verbose=False)\n",
        "cyphers_add_properties,nodes=add_properties(Outputs,nodes,name=None,verbose=False)\n",
        "exceute_cypher(graph,cyphers_add_properties,verbose=False)\n"
      ],
      "metadata": {
        "id": "e_AUvksVPjYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def add_relationships(relationships:Dict,entities,verbose=False):\n",
        "  cyphers=[]\n",
        "  for k,v in relationships.items():\n",
        "    v_=v\n",
        "    # if(k not in entities):\n",
        "    #   continue\n",
        "    k_=k.replace(\"'\",\"\").replace(\"-\",\"\")\n",
        "    if(type(v)==list)  :\n",
        "      v_=merge_dicts(v)\n",
        "    cypher=f\"Match (a{{name:'{k_}'}}) \"\n",
        "    for k1,v1 in v_.items():\n",
        "      print(k,k1)\n",
        "      print(\"V!!!!!!!\",v1)\n",
        "      if(type(v1)==str):\n",
        "        v1=v1.split(', ')\n",
        "\n",
        "      for v2 in v1:\n",
        "        if(type(v2)==str):\n",
        "          if(v2 not in entities):\n",
        "            continue\n",
        "          # print(v2,\" found in entities\")\n",
        "          v2=v2.replace(\"'\",\"\").replace(\"-\",\"\")\n",
        "          c2=f\"Match (b{{name:'{v2}'}}) \"\n",
        "          rel1=k1\n",
        "          cyphers.append(cypher +c2 + f\" Merge (a)-[:`{k1}`]->(b) \")\n",
        "  print(cyphers)\n",
        "  return cyphers"
      ],
      "metadata": {
        "id": "J3PMyZdEnvZ_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mentioned={}\n",
        "ent=[]"
      ],
      "metadata": {
        "id": "bOwgsEaOkGyo"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a in ['/content/json files/AMCs_ex_data_valid_entities.json','/content/json files/Debt_ex_data_valid_entities.json','/content/json files/Duration_ex_data_valid_entities.json','/content/json files/Equity_ex_data_valid_entities.json','/content/json files/Risk_ex_data_valid_entities.json']:\n",
        "  with open(a, 'r') as file:\n",
        "      retrieved_dict = json.load(file)\n",
        "  # pprint(retrieved_dict.keys())\n",
        "  # break\n",
        "  print(retrieved_dict.keys())\n",
        "  for k,v in retrieved_dict.items():\n",
        "    print('-------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
        "    # if('/content/HybridMF/Best Arbitrage Mutual Funds.txt'==k):\n",
        "    print(k)\n",
        "    # print(v[0])\n",
        "    e2=[temp.replace(\"'\",\"\").replace(\"-\",\"\") for temp in v[0]]\n",
        "    ent+=e2\n",
        "    mentioned[clean_string(extract_text(k)).replace(\"'\",\"\").replace(\"-\",\"\").upper()]={\"MENTIONS\":e2}\n",
        "mentioned\n"
      ],
      "metadata": {
        "id": "_FxuePbcTnff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rel_cyphers=add_relationships(mentioned,ent,verbose=False)\n",
        "exceute_cypher(graph,rel_cyphers,verbose=False)\n"
      ],
      "metadata": {
        "id": "a4segtVDnIL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory='/content/All Data'\n",
        "files=listdir(directory)\n",
        "files"
      ],
      "metadata": {
        "id": "le5XYT7Nod6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mEjDLmp5q70x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}